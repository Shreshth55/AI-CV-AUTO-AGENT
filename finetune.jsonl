{"input":"TASK: Detect phone usage in CCTV footage. ACTION: Generate a dataset plan.","output":"# Dataset Plan\n\n## Classes\n- person_using_phone: Person who is holding or interacting with a mobile phone (visible in frame).\n\n## Data sources\n- Roboflow search: \"person phone\", \"person holding phone\", \"mobile phone in hand\"\n- Public CCTV datasets, staged video captures, internal test recordings\n\n## Image counts\n- MVP: 800 images containing phone usage\n- Target: 2000 images for robust model\n\n## Split\n- Train: 70%\n- Val: 15%\n- Test: 15%\n\n## Augmentations\n- Horizontal flip (simulate left/right).\n- Brightness/contrast jitter (CCTV lighting)\n- Light motion blur (simulate low FPS)\n- Random crop/scale (vary person size)\n- Gaussian noise (low-quality CCTV)\n\n## File structure (YOLO format)\n- images/train/, images/val/, images/test/\n- labels/train/, labels/val/, labels/test/\n- data.yaml with classes and paths\n\n## Notes\n- Prefer frames where phone is visible near hand/face. Avoid far-away tiny phones if annotating is unreliable."}
{"input":"TASK: Detect phone usage in CCTV footage. ACTION: Generate a YOLO config.","output":"model: yolov8s.pt\nimgsz: 640\nbatch: 8\nepochs: 50\nlr0: 0.01\noptimizer: SGD\naugmentation:\n  - horizontal_flip: true\n  - brightness: [0.8,1.2]\n  - motion_blur: low\n  - gaussian_noise: true\nnotes: \"Start with yolov8s on Colab (T4). Increase to yolov8m for final runs if GPU allows.\""}
{"input":"TASK: Detect phone usage in CCTV footage. ACTION: Generate a training script outline.","output":"# train_yolo.py (outline)\n\n1. Parse args: --model, --data, --epochs, --imgsz, --batch\n2. from ultralytics import YOLO\n3. model = YOLO(args.model)\n4. model.train(data=args.data, epochs=args.epochs, imgsz=args.imgsz, batch=args.batch)\n5. Save best weights to runs/train/exp/weights/best.pt\n6. Run validation: model.val(data=args.data)\n7. Print mAP, precision, recall\n\n# Notes: set device=0 for GPU; use mixed precision if available."}
{"input":"TASK: Detect phone usage in CCTV footage. ACTION: Generate an ONNX + TensorRT optimization plan.","output":"# ONNX + TensorRT Optimization Plan\n\n1) Export to ONNX\n- Command (Ultralytics): model.export(format='onnx', imgsz=640)\n- Output: best.onnx\n\n2) ONNX Runtime benchmark\n- Use onnxruntime.InferenceSession to run batch inference and measure ms/frame\n\n3) Convert ONNX to TensorRT\n- trtexec --onnx=best.onnx --saveEngine=best.trt --fp16 --workspace=4096\n\n4) TensorRT inference\n- Write a simple TRT runner or use trtexec --loadEngine=best.trt --shapes=input:1x3x640x640 --batch=1\n\n5) Benchmark steps\n- Measure baseline (PyTorch) ms/frame\n- Measure ONNX ms/frame\n- Measure TensorRT ms/frame (FP16)\n- Record GPU utilization via: nvidia-smi --query-gpu=utilization.gpu,utilization.memory --format=csv -l 1\n\n6) Notes\n- Try FP16 first; consider INT8 only with a good calibration dataset.\n- Log results in a CSV for comparisons."}
{"input":"TASK: Detect phone usage in CCTV footage. ACTION: Generate README for the generated project.","output":"# Phone Usage Detection (Auto-Generated)\n\n## One-line\nDetect persons using mobile phones in CCTV footage; includes dataset plan, YOLO config, training script, and optimization steps.\n\n## Architecture\nUser prompt -> Planner LLM -> Generated artifacts (DATASET_PLAN.md, yolo_config.yaml, train_yolo.py, ONNX_TENSORRT_PLAN.md) -> User trains model -> Export/Optimize\n\n## How to use\n1. Follow DATASET_PLAN.md to collect and annotate data in YOLO format.\n2. Put dataset paths in data.yaml.\n3. Run train_yolo.py with correct args.\n4. Export to ONNX and optimize with TensorRT following ONNX_TENSORRT_PLAN.md.\n\n## Expected metrics\n- Baseline mAP: 0.5â€“0.7 (MVP)\n- Optimized GPU inference latency: target < 30 ms/frame on RTX 4090 (much lower on TensorRT)\n\n## Future work\n- Expand dataset, fine-tune the planner LLM, auto-run training from the planner."}
{"input":"TASK: Detect workers without helmets in factory. ACTION: Generate a dataset plan.","output":"# Dataset Plan\n\n## Classes\n- person_no_helmet: Worker not wearing a safety helmet\n- person_with_helmet (optional)\n\n## Sources\n- Roboflow keywords: 'helmet', 'no helmet', 'construction worker'\n- Public safety datasets and staged photos\n\n## Counts\n- MVP: 1000 images with clear helmet/no-helmet cases\n- Target: 3000 images\n\n## Split\n- Train 70% / Val 15% / Test 15%\n\n## Augmentations\n- Horizontal flip, brightness jitter, occlusion augmentation (simulate partial occlusions)\n\n## Notes\n- Label near-head bounding boxes; include full body for context."}
{"input":"TASK: Detect workers without helmets in factory. ACTION: Generate a YOLO config.","output":"model: yolov8s.pt\nimgsz: 640\nbatch: 8\nepochs: 60\nlr0: 0.01\noptimizer: SGD\nnotes: \"Use mosaic augmentation to increase rare negative samples (no-helmet)\""}
{"input":"TASK: Detect workers without helmets in factory. ACTION: Generate a training script outline.","output":"# train_yolo.py outline for helmet detection\n1. argparse for data, model, imgsz, epochs, batch\n2. from ultralytics import YOLO\n3. model = YOLO(MODEL_NAME)\n4. model.train(data='./data.yaml', epochs=EPOCHS, imgsz=IMGSZ, batch=BATCH)\n5. Save best.pt\n6. Run evaluation and print mAP\n\n# Additional: add class weights if dataset is class-imbalanced."}
{"input":"TASK: Detect workers without helmets in factory. ACTION: Generate ONNX + TensorRT plan.","output":"# ONNX/TensorRT Plan for Helmet Detection\n1) Export best.pt -> best.onnx via ultralytics export\n2) Use trtexec to create FP16 engine: trtexec --onnx=best.onnx --saveEngine=helmet_fp16.trt --fp16\n3) Benchmark CPU vs ONNX vs TRT; collect ms/frame and memory\n4) If INT8 considered: create a calibration set of 200 images\n5) Monitor GPU with nvidia-smi during benchmarks."}
{"input":"TASK: Detect workers without helmets in factory. ACTION: Generate README.","output":"# Helmet Detection Project (Auto-Generated)\n\n## Summary\nDetect workers without helmets using YOLO; includes training script and TensorRT optimization guide.\n\n## Quickstart\n- Prepare dataset according to DATASET_PLAN.md\n- Edit data.yaml\n- Run train_yolo.py\n- Export to ONNX and optimize with trtexec\n\n## Notes\n- Aim for mAP > 0.7 with expanded dataset; use class weighting to handle imbalance."}
{"input":"TASK: Detect parking violations from street cameras. ACTION: Generate a dataset plan.","output":"# Dataset Plan\n\n## Classes\n- parking_violation: car parked in no-parking area\n- normal_parking (optional)\n\n## Sources\n- Street camera snapshots, public parking datasets, synthetic overlays\n\n## Counts\n- MVP: 800 images\n- Target: 2500 images\n\n## Split\n- Train 70% / Val 15% / Test 15%\n\n## Augmentations\n- Brightness/contrast, random crop, perspective transform (simulate viewpoint changes)\n\n## Notes\n- Include clear ground-markings in images for robust detection."}
{"input":"TASK: Detect parking violations from street cameras. ACTION: Generate a YOLO config.","output":"model: yolov8s.pt\nimgsz: 640\nbatch: 6\nepochs: 50\nlr0: 0.01\noptimizer: AdamW\nnotes: \"Use larger batch if GPU allows; perspective augmentations are helpful.\""}
{"input":"TASK: Detect parking violations from street cameras. ACTION: Generate a training script outline.","output":"# train_yolo.py outline for parking violations\n1. argparse: --data, --model, --epochs, --imgsz\n2. from ultralytics import YOLO\n3. model = YOLO(MODEL_NAME)\n4. model.train(data=DATA, epochs=EPOCHS, imgsz=IMGSZ)\n5. Save best weights, evaluate on test set\n6. Output confusion matrix and mAP\n\n# Note: include code to visualize detections on sample frames."}
{"input":"TASK: Detect parking violations from street cameras. ACTION: Generate ONNX + TensorRT plan.","output":"# ONNX/TensorRT Plan\n1) Export ONNX via ultralytics export\n2) Build TRT engine using trtexec --onnx=best.onnx --saveEngine=parking_fp16.trt --fp16\n3) Use benchmark script: measure ms/frame and fps for batch=1\n4) Use nvidia-smi to log GPU usage\n\n# Tips: tune workspace and enable fp16 for major speedups."}
{"input":"TASK: Detect parking violations from street cameras. ACTION: Generate README.","output":"# Parking Violation Detection Project\n\n## One-liner\nDetect cars parked in prohibited zones using YOLO, with ONNX/TensorRT optimization steps included.\n\n## Quickstart\n- Follow DATASET_PLAN.md\n- Update data.yaml\n- Run train_yolo.py\n- Export to ONNX and create TRT engine\n\n## Metrics\n- Target latency: <50ms on an RTX-class GPU after optimization."}
{"input":"TASK: Detect smoke or fire in indoor CCTV. ACTION: Generate a dataset plan.","output":"# Dataset Plan\n\n## Classes\n- smoke_fire: visible smoke or flame\n- normal: no smoke\n\n## Sources\n- Fire/smoke public datasets, staged footage, synthetic augmentation\n\n## Counts\n- MVP: 800 images with smoke/fire\n- Target: 2500 images\n\n## Augmentations\n- Brightness/contrast, color jitter, gaussian noise\n\n## Split\n- Train 70% / Val 15% / Test 15%\n\n## Notes\n- Safety first: avoid any dangerous real fire capture; prefer staged/archival clips."}
{"input":"TASK: Detect smoke or fire in indoor CCTV. ACTION: Generate a YOLO config.","output":"model: yolov8s.pt\nimgsz: 640\nbatch: 8\nepochs: 60\nlr0: 0.01\noptimizer: AdamW\nnotes: \"Consider class weighting if smoke/fire samples are rare.\""}
{"input":"TASK: Detect smoke or fire in indoor CCTV. ACTION: Generate a training script outline.","output":"# train_yolo.py outline for fire detection\n1. argparse\n2. from ultralytics import YOLO\n3. model = YOLO(MODEL_NAME)\n4. model.train(...)\n5. Save weights; evaluate; send sample alerts for high-confidence detections\n\n# Notes: Use high recall threshold for alarm system; tune post-processing to reduce false positives."}
{"input":"TASK: Detect smoke or fire in indoor CCTV. ACTION: Generate ONNX + TensorRT plan.","output":"# ONNX/TensorRT Plan for Fire Detection\n1) Export ONNX\n2) Build TRT engine with fp16\n3) Benchmark and set low-latency threshold\n4) Use nvidia-smi to check utilization\n\n# Notes: prioritize recall over precision for early warning."}
{"input":"TASK: Detect smoke or fire in indoor CCTV. ACTION: Generate README.","output":"# Smoke/Fire Detection Project\n\n## Summary\nReal-time smoke/fire detection with YOLO and optimization steps for deployment.\n\n## Quickstart\n- Prepare dataset per DATASET_PLAN.md\n- Train model\n- Export and optimize with TensorRT\n\n## Safety\n- Tune thresholds to minimize false alarms; integrate with alerting systems."}
{"input":"TASK: Detect forklifts in warehouse aisles. ACTION: Generate a dataset plan.","output":"# Dataset Plan\n\n## Classes\n- forklift\n- person (optional)\n\n## Sources\n- Warehouse dashcam footage, staged captures, synthetic augmentation\n\n## Counts\n- MVP: 1000 forklift images\n- Target: 3000 images\n\n## Augmentations\n- Scale/crop, brightness jitter, occlusion augmentation\n\n## Split\n- Train 70% / Val 15% / Test 15%\n\n## Notes\n- Label entire forklift bounding box; include rotated views."}
{"input":"TASK: Detect forklifts in warehouse aisles. ACTION: Generate a YOLO config.","output":"model: yolov8s.pt\nimgsz: 640\nbatch: 8\nepochs: 60\nlr0: 0.01\noptimizer: SGD\nnotes: \"Use rotation augmentation and multi-scale training for varied forklifts.\""}
{"input":"TASK: Detect forklifts in warehouse aisles. ACTION: Generate a training script outline.","output":"# train_yolo.py outline for forklift detection\n1. argparse\n2. from ultralytics import YOLO\n3. model = YOLO(MODEL_NAME)\n4. model.train(...)\n5. Save weights and evaluate\n\n# Notes: consider adding per-class metrics and speed benchmarks."}
{"input":"TASK: Detect forklifts in warehouse aisles. ACTION: Generate an ONNX + TensorRT plan.","output":"# ONNX/TensorRT Plan for Forklift Detection\n1) Export ONNX\n2) Build TRT engine (fp16)\n3) Benchmark with sample video streams\n4) Log GPU utilization with nvidia-smi\n\n# Tips: measure FPS on actual edge device if targeting edge deployment."}
{"input":"TASK: Detect forklifts in warehouse aisles. ACTION: Generate README.","output":"# Forklift Detection Project\n\n## One-line\nDetect forklifts in warehouse aisles; includes training and optimization pipeline.\n\n## Quickstart\n- Follow dataset plan\n- Train using train_yolo.py\n- Export to ONNX and optimize with TensorRT\n\n## Notes\n- Visualize detections on sample frames to validate."}
