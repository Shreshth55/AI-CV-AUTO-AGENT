
You are a senior YOLO engineer.

Task:
Detect phone usage (person using a mobile phone) in indoor CCTV footage, such as offices or factories.

Design a YOLO training CONFIGURATION including:

1. Model variant (e.g., 'yolov8s', 'yolov8m') and justify the choice.
2. Image size (imgsz).
3. Batch size for a Colab T4 GPU.
4. Number of epochs for a first run, and for a more refined run.
5. Important hyperparameters (learning rate, optimizer, augmentations settings).
6. Any recommended YOLO training tricks (cosine LR, warmup, etc.).

Output:
First, give a YAML-style block with keys like:
- model
- imgsz
- batch
- epochs
- lr0
- optimizer
etc.

Then give a short explanation in Markdown.
```yaml
model: yolov8s
imgsz: 640
batch: 16
epochs: 10
lr0: 0.0001
optimizer: AdamW
augment: True
```

Explanation:
The `model` is chosen because it's lightweight yet powerful enough to handle the task of detecting phones in crowded environments. The image size (`imgsz`) is set at 640px to balance between accuracy and speed. A batch size of 16 is selected to take advantage of the computational power of the T4 GPU while ensuring efficient use of memory. For the initial run, I've set the number of epochs to 10, which should be sufficient to train the model on the dataset. The learning rate (`lr0`) is set to 0.0001, which is a common starting point but can be adjusted based on performance. The optimizer used is AdamW due to its good performance on many tasks. Finally, enabling data augmentation helps in capturing various types of images that might not have been seen during training. ```python
import cv2
from PIL import Image

# Load the pre-trained YOLOv8 model
net = cv2.dnn.readNet("path/to/your/yolo_model.h5")

def detect_phone_in_cctv(roi):
    # Convert ROI to RGB format if needed
    roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    
    # Create an input blob from the ROI image
    blob = cv2.dnn.blobFromImage(roi_rgb, 1 / 255, (640, 640), (127.5, 127.5, 127.5))
    
    # Set the input blob to the network
    net.setInput(blob)
    
    # Forward pass through the network
    detections = net.forward()
    
    # Check for detected objects
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        
        # Filter out weak detections
        if confidence > 0.5:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (centerX, centerY, width, height) = box.astype('int')
            
            x = int(centerX - (width / 2